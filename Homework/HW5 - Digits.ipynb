{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Dr D  \n",
    "Class: PHYS453 - Pattern Recognition \n",
    "Date: Spring 2020\n",
    "\n",
    "# HW5 - Digits Throwdown\n",
    "In this assignment you will check how well our classifiers work on hand-written numbers.  [Tutorial 10](https://github.com/mdaugherity/PatternRecognition2020/blob/master/Tutorial%2010%20-%20Digits%20Dataset.ipynb) shows how to use the digits dataset.  Use it to help you get started.\n",
    "\n",
    "# Tasks\n",
    "You will evaluate 3 different classifiers on the digits dataset.  You have some specific tasks for each one:\n",
    "1. GaussNB\n",
    "    * Fit the training set, then find the score and confusion matrix for the test set\n",
    "    * Use the `theta_` attribute to plot the average pixels for every number 0-9\n",
    "2. Nearest Neighbors\n",
    "    * Use the test data set to find the optimal value of k. Justify your answer.\n",
    "    * Show the 5 nearest neighbors to the first sample in the test set `X_test[0]`\n",
    "    * Show the 5 nearest neighbors to any one of the miss-classified points in the test set\n",
    "3. Decision Tree\n",
    "    * Use the test data set to find the optimal value of max_depth.  Justify your answer.\n",
    "    * Use the feature_importances_ attribute and make a plot showing the most important pixels\n",
    "4. Final Evaluation\n",
    "    * After completing the first three tasks, explain which classifier is **best** for the digits dataset.  Justify your answer.\n",
    "\n",
    "# Code\n",
    "The only fair way to evaluate classifier performance is to test them with data they haven't been trained where you know the right answers.  So we will using a **test / train split** as illustrated below.  Use this code without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_digits  \n",
    "from sklearn import metrics  # for confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load in the 1,797 samples from the data set and then split them (crudely):\n",
    "* the first 1,697 will be used for training\n",
    "* the last 100 will not be trained on and will only be used for testing the classifier's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:   (1797, 64) (1797,)\n",
      "Train:  (1697, 64) (1697,)\n",
      "Test:   (100, 64) (100,)\n"
     ]
    }
   ],
   "source": [
    "X,y = load_digits(return_X_y=True)\n",
    "\n",
    "# Do a crude test/train split to evaluate classifiers\n",
    "NUM_TEST = 100\n",
    "X_train = X[:-NUM_TEST] # use these for training\n",
    "y_train = y[:-NUM_TEST]\n",
    "X_test = X[-NUM_TEST:]  # use these for testing\n",
    "y_true = y[-NUM_TEST:]  # the right answers to check classifier's performance\n",
    "\n",
    "print(\"Data:  \",X.shape,y.shape)\n",
    "print(\"Train: \",X_train.shape, y_train.shape)\n",
    "print(\"Test:  \",X_test.shape,y_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may only use the `fit` function on X_train and y_train. If you try to fit the test data you will be immediately expelled. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
